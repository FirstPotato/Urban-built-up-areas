{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data introduction and import necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resolution:** 30m * 30m<br>\n",
    "**Target:** Target data set<br>\n",
    "**Point of Interest (POI):** POI Kernel Density, Resolution range: 250 m - 2500 m, interval = 250 m<br>\n",
    "**Road Network (RN):** Road Kernel Density, Resolution range: 250 m - 2500 m, interval = 250 m<br>\n",
    "**XM_Boundary:** mask of all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sl_1 import * # my custom module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate header named begin.txt from layer Target\n"
     ]
    }
   ],
   "source": [
    "# Extract and generate headers\n",
    "extrat_begin('Target', 'begin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ASCII to array and generate header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ASC_Data(file_name, ly_names):\n",
    "    '''input: file_name, a file name, parent file name of ly_names\n",
    "       input: ly_names, a list, list of layer names in an ASCII data format\n",
    "       output: ly_dict: a dictionary whose key is the layer name and the value is stored in an array format\n",
    "    '''     \n",
    "    ly_dict = {}\n",
    "    for name in ly_names:\n",
    "        ly_dict[name] = np.loadtxt('%s/%s.txt' % (file_name, name), skiprows = 6)\n",
    "    print('All ASCII data has been read')\n",
    "    return ly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_sme(start,mid,end):\n",
    "    '''input: start, start name of lyer name list\n",
    "    input: mid, middle name prefixs of lyer name list\n",
    "    input: end, end name of lyer name list\n",
    "    output: a lyer name list\n",
    "    '''\n",
    "    ly_name = [start]\n",
    "    ly_name += [mid + str(i) for i in range(250,2750,250)]\n",
    "    ly_name.append(end)\n",
    "    return ly_name\n",
    "# get_name_sme('Target','poi_all_','XM_Boundary') # test example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data consistency test\n",
    "Check whether there are missing values in different positions of the layer, <br>\n",
    "and auto fill it if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Na_Test(layer_names,stan_layer,ly_dict):\n",
    "    '''input: layer_names, a list of layer names to be checked for missing values\n",
    "       input: stan_layer, the normalized layer name used to verify that other layers have missing values\n",
    "       ly_dict: the dict data read by read_ASC_Data function.\n",
    "       output: For each layer in the name list, the following judgment is made. \n",
    "               If all the row raster cells of a layer are missing from the standard layer, \n",
    "               the layer is added to the result return list, \n",
    "               otherwise, the next layer is performed. Judgment.\n",
    "    '''\n",
    "    list1 = []\n",
    "    for name in layer_names:\n",
    "        # Fill in missing values start\n",
    "        ly_dict[name][np.where(ly_dict[name] == -9999)] = 0 # Fill all missing values (- 9999) with 0\n",
    "        ly_dict[name][np.where(ly_dict[stan_layer] == -9999)] = -9999 # Make - 9999 consistent with the standardized layer\n",
    "        # Fill in missing values end\n",
    "        a = max(ly_dict[name][np.where(ly_dict[stan_layer] == -9999)])\n",
    "        b = min(ly_dict[name][np.where(ly_dict[stan_layer] != -9999)])\n",
    "        if a == -9999 and b != -9999:\n",
    "            continue\n",
    "        else:\n",
    "            list1.append(name)\n",
    "    if len(list1) == 0:\n",
    "        print('All layers pass the inspection, no missing values exist, and are consistent with the standardized layer')\n",
    "    else:\n",
    "        print('The following layers have missing values')\n",
    "        print(list1)\n",
    "    return\n",
    "### test\n",
    "# test_name = get_name_sme('Target','poi_all_','XM_Boundary')\n",
    "# ly_dict = copy.deepcopy(read_ASC_Data('ASCII_POI', test_name))\n",
    "# Na_Test(test_name[:-1],test_name[-1],ly_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revel_array(dict_one):\n",
    "    '''input: dict_one, a dictionary whose key is the layer name and the value is stored in an array format\n",
    "       output: A dict whose value is all converted to one-dimensional array\n",
    "    '''\n",
    "    new_dict = copy.deepcopy(dict_one)\n",
    "    for key,value in new_dict.items():\n",
    "        new_dict[key] = np.ravel(value, order='C') # Expand to one dimension by row\n",
    "    num_rows = len(list(new_dict.values())[0])\n",
    "    new_dict['ID'] = np.array([i for i in range(num_rows)]) # Build index with name ID\n",
    "    return new_dict\n",
    "\n",
    "# ly_dict_reval = revel_array(ly_dict)\n",
    "# ly_dict_reval\n",
    "# len(ly_dict_reval['Target']) # show total number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conversion to dataframe and to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ly_df_csv(start,mid,end):\n",
    "    '''\n",
    "    input: start, start name of lyer name list\n",
    "    input: mid, middle name prefixs of lyer name list\n",
    "    input: end, end name of lyer name list\n",
    "    output: write a csv file of combined data from input file list\n",
    "    '''\n",
    "    ly_names = get_name_sme(start,mid,end)\n",
    "    if mid == 'poi_all_' or mid == 'poi_sel_':\n",
    "        name_asc = 'ASCII_POI'\n",
    "    else:\n",
    "        name_asc = 'ASCII_RN'\n",
    "    ly_dict0 = read_ASC_Data(name_asc, ly_names) # read ASCII data\n",
    "    ly_dict = copy.deepcopy(ly_dict0)\n",
    "#     print(ly_dict['Target'])\n",
    "#     print(np.shape(ly_dict['Target']))\n",
    "    test_name = ly_names\n",
    "    Na_Test(test_name[:-1],test_name[-1], ly_dict)\n",
    "    ly_dict_reval = revel_array(ly_dict) # Dimension reduction\n",
    "#     print(len(ly_dict_reval['Target'])) # show total number of records\n",
    "    ly_df = pd.DataFrame(ly_dict_reval,columns=ly_dict_reval.keys())\n",
    "    write_name = 'bw_' + mid[:-1]\n",
    "    ly_df.to_csv(r'data\\%s.csv' % (write_name),index = False)\n",
    "    return\n",
    "# start = 'Target'\n",
    "# end = 'XM_Boundary'\n",
    "# mid = 'poi_all_'\n",
    "# ly_df_csv(start,mid,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write three csv data\n",
    "- bw_poi_all\n",
    "- bw_poi_sel\n",
    "- bw_RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step spend about five minutes overall\n",
    "start = 'Target'\n",
    "end = 'XM_Boundary'\n",
    "for mid in ['poi_all_', 'poi_sel_', 'RN_']:\n",
    "    ly_df_csv(start,mid,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Urban Built-up Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import sklearn libraries and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# import graphviz \n",
    "# import pydotplus\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The effect of bandwidth of POI and Road network on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(ind, node_num, input_data,Train,Test):\n",
    "    '''\n",
    "    Returns the decision tree accuracy calculated for different layers based on different bandwidth estimates\n",
    "    '''\n",
    "    x_features = input_data.iloc[:,[ind]].columns\n",
    "    y_col = 'Target'\n",
    "    X_Train = Train[x_features].copy()\n",
    "    X_Test = Test[x_features].copy()\n",
    "    Y_Train = Train[[y_col]].copy()\n",
    "    Y_Test = Test[[y_col]].copy() # Get sub dataframe\n",
    "    clf = DecisionTreeClassifier(max_leaf_nodes=node_num, random_state=1)\n",
    "    clf.fit(X_Train, Y_Train)\n",
    "    predictions = clf.predict(X_Test)\n",
    "#     acc = accuracy_score(y_true = Y_Test, y_pred = predictions)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true = Y_Test, y_pred = predictions).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return f1_score\n",
    "# [get_acc(i,2) for i in range(1,11)]\n",
    "# max_leaf_nodes=2, random_state=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BW_POI_RN():\n",
    "    '''\n",
    "    output: write a csv file of bandwidth of POI and Road network on accuracy\n",
    "    '''\n",
    "    dict0 = {}\n",
    "    dict0['BandWidth'] = list(range(250,2750,250))\n",
    "    name_list1 = ['bw_poi_all', 'bw_poi_sel', 'bw_RN']\n",
    "    name_list2 = ['POI_All','POI_Sel','RN']\n",
    "    for i in range(3):\n",
    "        name1 = name_list1[i]\n",
    "        name2 = name_list2[i]\n",
    "        ly_df = pd.read_csv(r'data\\%s.csv' % (name1))\n",
    "        data = ly_df.copy()\n",
    "#         print(data.columns)\n",
    "        clean_data = data.copy()\n",
    "        clean_data = clean_data[clean_data.loc[:,'Target'] != -9999]\n",
    "#         print(clean_data.head())\n",
    "        # Perform Test and Train split\n",
    "        input_data = clean_data.copy()\n",
    "        Train, Test = train_test_split(clean_data, test_size=0.33, random_state=160)\n",
    "        input_data = clean_data.copy()\n",
    "        acc_scores = [get_acc(i,2,input_data,Train,Test) for i in range(1,11)]\n",
    "        dict0[name2] = acc_scores\n",
    "    df_POI_RN = pd.DataFrame(dict0)\n",
    "    df_POI_RN.to_csv(r'data\\BandWidth_POI_RN.csv',index = False)\n",
    "BW_POI_RN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217.058px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
